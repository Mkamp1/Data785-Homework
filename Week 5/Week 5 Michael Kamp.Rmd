---
title: "Logistic Regression and Naive Bayes with Auto Dataset"
author: "Michael Kamp"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
## Introduction

In this assignment, I will use the Auto data set to compare two classification methods: Logistic Regression and Naive Bayes. I will predict whether a car’s mpg is above the median (mpg01) using selected predictors, and evaluate performance using confusion matrices and accuracy.

```{r Load-Data, message=FALSE, warning=FALSE}
# Load libraries quietly
library(ISLR2)
library(e1071)
library(caret)
library(ggplot2)

# Load Auto data set
data(Auto)

# Create binary response mpg01
Auto$mpg01 <- ifelse(Auto$mpg > median(Auto$mpg), 1, 0)

# Create training and test sets (Week 1 split)
set.seed(1)
train <- sample(1:nrow(Auto), nrow(Auto)/2)
test <- -train

Auto_train <- Auto[train, ]
Auto_test  <- Auto[test, ]

```
## Question 1: Logistic Regression vs Naive Bayes

```{r Logistic-Regression}
# Logistic Regression
glm_fit <- glm(mpg01 ~ cylinders + horsepower + weight, 
               data = Auto_train, family = binomial)

glm_probs <- predict(glm_fit, Auto_test, type = "response")
glm_pred <- ifelse(glm_probs > 0.5, 1, 0)

# Confusion matrix & accuracy
confusionMatrix(as.factor(glm_pred), as.factor(Auto_test$mpg01))$table

# Accuracy
glm_acc <- mean(glm_pred == Auto_test$mpg01)
glm_acc
```
```{r Naive-Bayes}
# Naive Bayes
nb_fit_q1 <- naiveBayes(mpg01 ~ cylinders + horsepower + weight, data = Auto_train)

nb_pred_q1 <- predict(nb_fit_q1, Auto_test)

# Cleaner confusion matrix
confusionMatrix(as.factor(nb_pred_q1), as.factor(Auto_test$mpg01))$table

# Accuracy
nb_acc <- mean(nb_pred_q1 == Auto_test$mpg01)
nb_acc
```

```{r Accuracy-Comparison}
# Accuracy Comparison
results_q1 <- data.frame(
  Model = c("Logistic Regression", "Naive Bayes"),
  Accuracy = c(glm_acc, nb_acc)
)

# Show results as table
results_q1

# Bar chart for visual comparison
ggplot(results_q1, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(Accuracy, 3)), vjust = -0.5, size = 5) +
  labs(title = "Model Accuracy Comparison", y = "Accuracy", x = "Model") +
  ylim(0, 1) +
  theme_minimal() +
  theme(legend.position = "none")
```

## Conclusion

Logistic Regression achieved an accuracy of about `r round(glm_acc * 100, 2)`%,  
while Naive Bayes achieved an accuracy of about `r round(nb_acc * 100, 2)`%.  

Both models performed similarly, with Logistic Regression slightly higher.  
This suggests either method provides strong performance for predicting whether a car’s mpg is above or below the median.

## Question 14(g): Naive Bayes with Auto Dataset

```{r naive-bayes-14g}
# Fit Naive Bayes model
nb_fit <- naiveBayes(mpg01 ~ cylinders + horsepower + weight, data = Auto_train)

# Predict on test data
nb_pred <- predict(nb_fit, Auto_test)

# Confusion matrix
confusionMatrix(as.factor(nb_pred), as.factor(Auto_test$mpg01))$table

# Test error
nb_test_error <- mean(nb_pred != Auto_test$mpg01)
nb_test_error
```
## Conclusion

In Problem 14(g), I applied a Naive Bayes classifier to the Auto data set using the training/test split defined earlier. The predictors selected (`cylinders`, `horsepower`, and `weight`) were those most associated with `mpg01` from part (b).

The model’s predictions on the test set produced the confusion matrix shown above. The overall test error rate was approximately `r round(nb_test_error * 100, 2)`%, meaning the model misclassified about that percentage of the test observations.

This indicates that the Naive Bayes approach performs reasonably well in distinguishing cars with above-median mpg from those with below-median mpg.  

---

### Final Takeaway  

Overall, both Logistic Regression and Naive Bayes provided strong predictive performance on the Auto data set, with Logistic Regression showing slightly higher accuracy and Naive Bayes demonstrating a low test error rate. These results suggest that either approach is effective for classifying cars by above- or below-median mpg.











